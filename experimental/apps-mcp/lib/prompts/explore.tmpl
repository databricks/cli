{{- /*
     * Guidance for exploring Databricks workspaces and resources.
     *
     * This guidance is offered by the explore tool to provide comprehensive
     * instructions for discovering and querying workspace resources like
     * jobs, clusters, catalogs, tables, and SQL warehouses.
     *
     */ -}}

Databricks Data Exploration Guide
=====================================

{{.WorkspaceInfo}}{{if .WarehouseName}}
Default SQL Warehouse: {{.WarehouseName}} ({{.WarehouseID}}){{else}}
Note: No SQL warehouse detected. SQL queries will require warehouse_id to be specified manually.{{end}}{{.ProfilesInfo}}

IMPORTANT: Use the invoke_databricks_cli tool to run all commands below!

QUICK START - DATA DISCOVERY
=============================

‚ö° EFFICIENT 4-STEP WORKFLOW:

1. Find available catalogs:
   invoke_databricks_cli 'catalogs list'

2. Find schemas in a catalog:
   invoke_databricks_cli 'schemas list <catalog_name>'

3. Find tables in a schema:
   invoke_databricks_cli 'tables list <catalog_name> <schema_name>'

4. Batch discover multiple tables (ONE call for efficiency):
   invoke_databricks_cli 'experimental apps-mcp tools discover-schema TABLE1 TABLE2 TABLE3'

   ‚ö° Always use batch mode: Discover multiple tables in ONE call instead of separate calls
   Table format: CATALOG.SCHEMA.TABLE (e.g., samples.nyctaxi.trips)

QUICK SQL EXECUTION:
   Execute SQL and get JSON results:
   invoke_databricks_cli 'experimental apps-mcp tools query "SELECT * FROM catalog.schema.table LIMIT 10"'

‚ö†Ô∏è COMMON ERRORS:
‚ùå Wrong: invoke_databricks_cli 'tables list samples.tpcds_sf1'
‚úÖ Correct: invoke_databricks_cli 'tables list samples tpcds_sf1'
   (Use separate arguments, not dot notation for catalog and schema)

üìö For detailed information on each command, see sections below.


1. EXECUTING SQL QUERIES
   Execute SQL queries using the query tool (recommended):
     invoke_databricks_cli 'experimental apps-mcp tools query "SELECT * FROM catalog.schema.table LIMIT 10"'

2. EXPLORING JOBS AND WORKFLOWS
   List all jobs:
     invoke_databricks_cli 'jobs list'

   Get job details:
     invoke_databricks_cli 'jobs get <job_id>'

   List job runs:
     invoke_databricks_cli 'jobs list-runs --job-id <job_id>'


3. EXPLORING CLUSTERS
   List all clusters:
     invoke_databricks_cli 'clusters list'

   Get cluster details:
     invoke_databricks_cli 'clusters get <cluster_id>'


4. EXPLORING UNITY CATALOG DATA
   Unity Catalog uses a three-level namespace: catalog.schema.table

   List all catalogs:
     invoke_databricks_cli 'catalogs list'

   List schemas in a catalog:
     invoke_databricks_cli 'schemas list <catalog_name>'

   List tables in a schema:
     invoke_databricks_cli 'tables list <catalog_name> <schema_name>'

   Get table details (schema, columns, properties):
     invoke_databricks_cli 'tables get <catalog>.<schema>.<table>'

   Discover table schema with samples (recommended):
     Batch discover multiple tables in ONE call:
       invoke_databricks_cli 'experimental apps-mcp tools discover-schema catalog.schema.table1 catalog.schema.table2'

     Single table:
       invoke_databricks_cli 'experimental apps-mcp tools discover-schema catalog.schema.table'

5. EXPLORING WORKSPACE FILES
   List workspace files and notebooks:
     invoke_databricks_cli 'workspace list <path>'

   Export a notebook:
     invoke_databricks_cli 'workspace export <path>'


Getting Started:
- Use the commands above to explore what resources exist in the workspace
- All commands support --output json for programmatic access
- Remember to add --profile <name> when working with non-default workspaces


DATABRICKS ASSET BUNDLES (DABs) WORKFLOW
=========================================

Creating a New Bundle Project:
  When to use: Building a new project from scratch with deployment to multiple environments

  1. Initialize a new bundle (creates proper project structure):
     invoke_databricks_cli 'bundle init'

  2. Validate the bundle configuration:
     invoke_databricks_cli 'bundle validate'

  3. Deploy to a target environment (dev/staging/prod):
     invoke_databricks_cli 'bundle deploy --target dev'

Working with Existing Bundle Project:
  When to use: databricks.yml file already exists in the directory

  1. Validate changes:
     invoke_databricks_cli 'bundle validate'

  2. Deploy to environment:
     invoke_databricks_cli 'bundle deploy --target <environment>'

  3. Run a resource (job/pipeline):
     invoke_databricks_cli 'bundle run <resource_name>'

  4. Destroy deployed resources:
     invoke_databricks_cli 'bundle destroy --target <environment>'

Bundle Commands Reference:
  - bundle init                    # Initialize new bundle from template
  - bundle validate                # Validate bundle configuration
  - bundle deploy                  # Deploy bundle to workspace
  - bundle run <resource>          # Run a job or pipeline
  - bundle destroy                 # Remove deployed resources
  - bundle schema                  # Show bundle configuration schema

üí° Tip: Use 'invoke_databricks_cli bundle init' to see available templates


COMMON PATTERNS
===============

Multi-environment deployment:
  Deploy to different environments using targets in databricks.yml:
    invoke_databricks_cli 'bundle deploy --target dev'
    invoke_databricks_cli 'bundle deploy --target prod'

Working with pipelines/jobs in bundles:
  Add resources to databricks.yml, then:
    invoke_databricks_cli 'bundle validate'
    invoke_databricks_cli 'bundle deploy'
    invoke_databricks_cli 'bundle run <job_name>'


BEST PRACTICES
==============

‚úÖ DO use invoke_databricks_cli for all Databricks CLI commands
   (Better for user allowlisting and tracking)

‚úÖ DO use 'experimental apps-mcp tools query' for SQL execution
   (Auto-wait, clean JSON output, no manual polling)

‚úÖ DO use batch discover-schema for multiple tables
   (One call instead of multiple: more efficient)

‚úÖ DO test SQL with query tool before implementing in code
   (Verify syntax and results interactively)

‚úÖ DO use 'experimental apps-mcp tools init-template your-app-name' for new projects
   (Faster scaffolding with auto-configured warehouse)

‚úÖ DO validate bundles before deploying:
   invoke_databricks_cli 'bundle validate'

‚úÖ DO use bundle templates for new projects:
   invoke_databricks_cli 'bundle init'

‚úÖ DO call explore during planning to get workspace context
