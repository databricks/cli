{{- /*
     * L1: Universal workflow guidance for Databricks MCP.
     *
     * This guidance is always provided by databricks_discover.
     * Contains: available tools, CLI patterns, best practices.
     */ -}}

## Databricks MCP Available Tools
- **databricks_discover**: Discover workspace resources and get workflow recommendations
- **databricks_configure_auth**: Switch workspace profile/host
- **invoke_databricks_cli**: Execute any Databricks CLI command

## Workflow Best Practices
- Use `databricks_discover` at the beginning of your session to get context-aware recommendations
- For operations affecting live environments, ask for confirmation
- Always validate before deploying
- When not sure about the user's intent, ask clarifying questions

{{.WorkspaceInfo}}{{if .WarehouseName}}
Default SQL Warehouse: {{.WarehouseName}} ({{.WarehouseID}}){{else}}
Note: No SQL warehouse detected. SQL queries will require warehouse_id to be specified manually.{{end}}{{.ProfilesInfo}}

## Universal Databricks CLI Patterns
Use `invoke_databricks_cli '<command>'` to run any Databricks CLI command.

### Project scaffolding

IMPORTANT: Always use 'experimental apps-mcp tools init-template' commands below instead of 'databricks bundle init'.
The init-template commands create agent-friendly projects with AGENTS.md/CLAUDE.md guidance files and proper MCP integration.

For apps:
invoke_databricks_cli 'experimental apps-mcp tools init-template app --name my-app --description "My app description"'

For jobs (Python notebooks with wheel package):
invoke_databricks_cli 'experimental apps-mcp tools init-template job --name my_job'
invoke_databricks_cli 'experimental apps-mcp tools init-template job --name my_job --catalog my_catalog'

For pipelines (Lakeflow Declarative Pipelines):
invoke_databricks_cli 'experimental apps-mcp tools init-template pipeline --name my_pipeline --language python'
invoke_databricks_cli 'experimental apps-mcp tools init-template pipeline --name my_pipeline --language sql --catalog my_catalog'
Note: --language is required (python or sql)

For custom resources (dashboards, alerts, model serving, etc.):
invoke_databricks_cli 'experimental apps-mcp tools init-template empty --name my_project'
Note: Use this for resources OTHER than apps, jobs, or pipelines

Notes:
- App name must be â‰¤26 characters (dev- prefix adds 4 chars, max total 30)
- Job/pipeline/project names: letters, numbers, underscores only
- --catalog defaults to workspace default catalog{{if .DefaultCatalog}} (currently '{{.DefaultCatalog}}'){{end}}

### Custom SQL Queries

invoke_databricks_cli 'experimental apps-mcp tools query "SELECT * FROM catalog.schema.table LIMIT 10"'

### Exploring Resources
Jobs:
  invoke_databricks_cli 'jobs list'
  invoke_databricks_cli 'jobs get <job_id>'

Clusters:
  invoke_databricks_cli 'clusters list'

Unity Catalog:
  invoke_databricks_cli 'catalogs list'
  invoke_databricks_cli 'schemas list <catalog>'
  invoke_databricks_cli 'tables list <catalog> <schema>'
  invoke_databricks_cli 'experimental apps-mcp tools discover-schema TABLE1 TABLE2 TABLE3'

Use separate arguments for catalog/schema: 'tables list samples tpcds_sf1' (not dot notation).
Dot notation is only supported in `experimental apps-mcp tools discover-schema` and `experimental apps-mcp tools query`.

It is STRONGLY RECOMMENDED to delegate the task of exploring catalogs, schemas, or tables in Unity Catalog to an Explore agent or a sub agent.
