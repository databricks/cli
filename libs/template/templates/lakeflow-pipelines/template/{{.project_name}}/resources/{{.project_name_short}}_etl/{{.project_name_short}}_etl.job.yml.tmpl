{{/* For Lakeflow Pipelines, we only include a simple job.yml
   * directly in resources/{{.project_name_short}}_etl
   */ -}}
# The job that triggers {{.project_name_short}}_etl.
resources:
  jobs:
    {{.project_name_short}}_job:
      name: {{.project_name_short}}_job

      trigger:
        # Run this job every day, exactly one day from the last run; see https://docs.databricks.com/api/workspace/jobs/create#trigger
        periodic:
          interval: 1
          unit: DAYS

      #email_notifications:
      #  on_failure:
      #    - your_email@example.com

      tasks:
        - task_key: refresh_pipeline
          pipeline_task:
            pipeline_id: ${resources.pipelines.{{.project_name_short}}_etl.id}
