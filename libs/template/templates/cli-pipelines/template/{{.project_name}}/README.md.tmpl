# {{.project_name}}

The '{{.project_name}}' project was generated by using the CLI Pipelines template.

## Setup

1. Install the Databricks CLI from https://docs.databricks.com/dev-tools/cli/databricks-cli.html

2. Install the Pipelines CLI:
   ```
   $ databricks install-pipelines-cli
   ```

3. Authenticate to your Databricks workspace, if you have not done so already:
    ```
    $ pipelines auth login
    ```

4. Optionally, install developer tools such as the Databricks extension for Visual Studio Code from
   https://docs.databricks.com/dev-tools/vscode-ext.html. Or the PyCharm plugin from
   https://www.databricks.com/blog/announcing-pycharm-integration-databricks.

## Pipeline Structure

This folder defines all source code for the {{template `pipeline_name` .}} pipeline:

{{ if (eq .language "python") -}}
- `explorations`: Ad-hoc notebooks used to explore the data processed by this pipeline.
- `transformations`: All dataset definitions and transformations.
- `utilities` (optional): Utility functions and Python modules used in this pipeline.
- `data_sources` (optional): View definitions describing the source data for this pipeline.
{{- else -}}
- `explorations`: Ad-hoc notebooks used to explore the data processed by this pipeline.
- `transformations`: All dataset definitions and transformations.
- `data_sources` (optional): View definitions describing the source data for this pipeline.
{{- end }}

## Getting Started

To get started, go to the `transformations` folder -- most of the relevant source code lives there:

{{ if (eq .language "python") -}}
* By convention, every dataset under `transformations` is in a separate file.
* Take a look at the sample under "sample_trips_{{ .project_name }}.py" to get familiar with the syntax.
  Read more about the syntax at https://docs.databricks.com/dlt/python-ref.html.
{{- else -}}
* By convention, every dataset under `transformations` is in a separate file.
* Take a look at the sample under "sample_trips_{{ .project_name }}.sql" to get familiar with the syntax.
  Read more about the syntax at https://docs.databricks.com/dlt/sql-ref.html.
{{- end }}

For more tutorials and reference material, see https://docs.databricks.com/dlt.

## Deploying pipelines

1. To deploy a development copy of this project, type:
    ```
    $ pipelines deploy --target dev
    ```
    (Note that "dev" is the default target, so the `--target` parameter
    is optional here.)

2. Similarly, to deploy a production copy, type:
   ```
   $ pipelines deploy --target prod
   ```

3. To run a pipeline, use the "run" command:
   ```
   $ pipelines run
   ```
