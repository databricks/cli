# my_project

The 'my_project' project was generated by using the CLI Pipelines template.

## Setup

1. Install the Databricks CLI from https://docs.databricks.com/dev-tools/cli/databricks-cli.html

2. Install the Pipelines CLI:
   ```
   $ databricks install-pipelines-cli
   ```

3. Authenticate to your Databricks workspace, if you have not done so already:
    ```
    $ pipelines auth login
    ```

4. Optionally, install developer tools such as the Databricks extension for Visual Studio Code from
   https://docs.databricks.com/dev-tools/vscode-ext.html. Or the PyCharm plugin from
   https://www.databricks.com/blog/announcing-pycharm-integration-databricks.


## Deploying pipelines

1. To deploy a development copy of this project, type:
    ```
    $ pipelines deploy --target dev
    ```
    (Note that "dev" is the default target, so the `--target` parameter
    is optional here.)

2. Similarly, to deploy a production copy, type:
   ```
   $ pipelines deploy --target prod
   ```

3. To run a pipeline, use the "run" command:
   ```
   $ pipelines run
   ```

## Pipeline Structure

This folder defines all source code for the my_project_pipeline pipeline:

- `explorations`: Ad-hoc notebooks used to explore the data processed by this pipeline.
- `transformations`: All dataset definitions and transformations.
- `utilities`: Utility functions and Python modules used in this pipeline.

## Getting Started

To get started, go to the `transformations` folder -- most of the relevant source code lives there:* By convention, every dataset under `transformations` is in a separate file.
* Take a look at the sample under "sample_trips_my_project.py" to get familiar with the syntax.
  Read more about the syntax at https://docs.databricks.com/dlt/python-ref.html.
* Use `Run file` to run and preview a single transformation.
* Use `Run pipeline` to run _all_ transformations in the entire pipeline.
* Use `+ Add` in the file browser to add a new data set definition.
* Use `Schedule` to run the pipeline on a schedule!

For more tutorials and reference material, see https://docs.databricks.com/dlt.
