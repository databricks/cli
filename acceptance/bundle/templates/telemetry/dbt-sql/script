$CLI bundle init dbt-sql --config-file input.json --output-dir output

# We only need to keep the output databricks.yml to assert the bundle_uuid is consistent
# in both the generated YAML file and telemetry payload.
mv output/my_dbt_sql/databricks.yml out.databricks.yml
rm -r output

# Disable pipefail. head can exit early if it encounters a new line. That would cause a SIGPIPE in linux systems.
set +o pipefail
cmd_exec_id=$(cat out.requests.txt | jq '.headers."User-Agent".[0]'| head -n 1 | grep -o 'cmd-exec-id/[^ ]*' | cut -d '/' -f2)
bundle_uuid=$(cat out.databricks.yml | grep -o 'uuid: [^\n]*' | cut -d ' ' -f2)

update_file.py out.requests.txt $cmd_exec_id  '[CMD-EXEC-ID]'
update_file.py out.requests.txt $bundle_uuid '[BUNDLE-UUID]'
update_file.py out.databricks.yml $bundle_uuid '[BUNDLE-UUID]'

# pretty print the telemetry payload.
trace cat out.requests.txt | jq 'select(has("path") and .path == "/telemetry-ext") | .body.protoLogs.[] | fromjson'
