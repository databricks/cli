# my_lakeflow_pipelines

The 'my_lakeflow_pipelines' project was generated by using the Lakeflow Pipelines template.

## Setup

1. Install the Databricks CLI from https://docs.databricks.com/dev-tools/cli/databricks-cli.html

2. Authenticate to your Databricks workspace, if you have not done so already:
    ```
    $ databricks auth login
    ```

3. Optionally, install developer tools such as the Databricks extension for Visual Studio Code from
   https://docs.databricks.com/dev-tools/vscode-ext.html. Or the PyCharm plugin from
   https://www.databricks.com/blog/announcing-pycharm-integration-databricks.


## Deploying resources

1. To deploy a development copy of this project, type:
    ```
    $ databricks bundle deploy --target dev
    ```
    (Note that "dev" is the default target, so the `--target` parameter
    is optional here.)

2. Similarly, to deploy a production copy, type:
   ```
   $ databricks bundle deploy --target prod
   ```

3. Use the "summary" comand to review everything that was deployed:
   ```
   $ databricks bundle summary
   ```

4. To run a job or pipeline, use the "run" command:
   ```
   $ databricks bundle run
   ```
