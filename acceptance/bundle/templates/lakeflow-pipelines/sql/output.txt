
>>> [CLI] bundle init lakeflow-pipelines --config-file ./input.json --output-dir output
Welcome to the template for Lakeflow Spark Declarative Pipelines!

Please answer the below to tailor your project to your preferences.
You can always change your mind and change your configuration in the databricks.yml file later.

Note that [DATABRICKS_URL] is used for initialization
(see https://docs.databricks.com/dev-tools/cli/profiles.html for how to change your profile).

âœ¨ Your new project has been created in the 'my_lakeflow_pipelines' directory!

Please refer to the README.md file for "getting started" instructions.

>>> [CLI] bundle validate -t dev
Name: my_lakeflow_pipelines
Target: dev
Workspace:
  Host: [DATABRICKS_URL]
  User: [USERNAME]
  Path: /Workspace/Users/[USERNAME]/.bundle/my_lakeflow_pipelines/dev

Validation OK!

>>> [CLI] bundle validate -t prod
Name: my_lakeflow_pipelines
Target: prod
Workspace:
  Host: [DATABRICKS_URL]
  User: [USERNAME]
  Path: /Workspace/Users/[USERNAME]/.bundle/my_lakeflow_pipelines/prod

Validation OK!
