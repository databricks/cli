envsubst < databricks.yml.tmpl > databricks.yml

cleanup() {
    trace $CLI bundle destroy --auto-approve
    rm out.requests.txt
}
trap cleanup EXIT

trace $CLI bundle deploy

title "Cluster should exist after bundle deployment:\n"
CLUSTER_ID=$($CLI bundle summary -o json | jq -r '.resources.clusters.test_cluster.id')
$CLI clusters get "${CLUSTER_ID}" | jq '{cluster_name,num_workers}'

title "Changing num_workers should call update API on stopped cluster\n"
update_file.py databricks.yml "num_workers: 2" "num_workers: 3"
trace $CLI bundle deploy
trace jq 'select(.method == "POST" and (.path | contains("/clusters/edit")))' out.requests.txt
rm out.requests.txt

title "Cluster should have new num_workers\n"
$CLI clusters get "${CLUSTER_ID}" | jq '{cluster_name,num_workers}'

title "Starting the cluster\n"
$CLI clusters start "${CLUSTER_ID}"

title "Changing num_workers should call resize API on running cluster\n"
update_file.py databricks.yml "num_workers: 3" "num_workers: 4"
trace $CLI bundle deploy
trace jq 'select(.method == "POST" and (.path | contains("/clusters/resize")))' out.requests.txt
rm out.requests.txt

title "Cluster should have new num_workers\n"
$CLI clusters get "${CLUSTER_ID}" | jq '{cluster_name,num_workers}'

title "Changing num_workers and spark_conf should call update API\n"
update_file.py databricks.yml "num_workers: 4" "num_workers: 5"
update_file.py databricks.yml '"spark.executor.memory": "2g"' '"spark.executor.memory": "4g"'
trace $CLI bundle deploy
trace jq 'select(.method == "POST" and (.path | contains("/clusters/edit")))' out.requests.txt
rm out.requests.txt

title "Cluster should have new num_workers and spark_conf\n"
$CLI clusters get "${CLUSTER_ID}" | jq '{cluster_name,num_workers,spark_conf}'
