
>>> [CLI] bundle deploy
Uploading bundle files to /Workspace/Users/[USERNAME]/.bundle/[UNIQUE_NAME]/files...
Deploying resources...
Updating deployment state...
Deployment complete!

=== Cluster should exist with num_workers after bundle deployment:
{
  "cluster_name": "test-cluster-[UNIQUE_NAME]",
  "num_workers": 2,
  "autoscale": null
}

=== Adding autoscale section should call update API on stopped cluster

>>> [CLI] bundle deploy
Uploading bundle files to /Workspace/Users/[USERNAME]/.bundle/[UNIQUE_NAME]/files...
Deploying resources...
Updating deployment state...
Deployment complete!

>>> jq select(.method == "POST" and (.path | contains("/clusters/edit"))) out.requests.txt
{
  "method": "POST",
  "path": "/api/2.1/clusters/edit",
  "body": {
    "autoscale": {
      "max_workers": 4,
      "min_workers": 2
    },
    "autotermination_minutes": 60,
    "cluster_id": "[CLUSTER_ID]",
    "cluster_name": "test-cluster-[UNIQUE_NAME]",
    "node_type_id": "[NODE_TYPE_ID]",
    "spark_version": "13.3.x-snapshot-scala2.12"
  }
}

=== Cluster should have autoscale
{
  "cluster_name": "test-cluster-[UNIQUE_NAME]",
  "num_workers": null,
  "autoscale": {
    "max_workers": 4,
    "min_workers": 2
  }
}

=== Changing autoscale should call update API on stopped cluster

>>> [CLI] bundle deploy
Uploading bundle files to /Workspace/Users/[USERNAME]/.bundle/[UNIQUE_NAME]/files...
Deploying resources...
Updating deployment state...
Deployment complete!

>>> jq select(.method == "POST" and (.path | contains("/clusters/edit"))) out.requests.txt
{
  "method": "POST",
  "path": "/api/2.1/clusters/edit",
  "body": {
    "autoscale": {
      "max_workers": 5,
      "min_workers": 3
    },
    "autotermination_minutes": 60,
    "cluster_id": "[CLUSTER_ID]",
    "cluster_name": "test-cluster-[UNIQUE_NAME]",
    "node_type_id": "[NODE_TYPE_ID]",
    "spark_version": "13.3.x-snapshot-scala2.12"
  }
}

=== Cluster should have new autoscale
{
  "cluster_name": "test-cluster-[UNIQUE_NAME]",
  "num_workers": null,
  "autoscale": {
    "max_workers": 5,
    "min_workers": 3
  }
}

=== Starting the cluster
{
  "autoscale": {
    "max_workers":5,
    "min_workers":3
  },
  "autotermination_minutes":60,
  "cluster_id":"[CLUSTER_ID]",
  "cluster_name":"test-cluster-[UNIQUE_NAME]",
  "node_type_id":"[NODE_TYPE_ID]",
  "spark_version":"13.3.x-snapshot-scala2.12",
  "state":"RUNNING"
}

=== Changing autoscale should call resize API on running cluster

>>> [CLI] bundle deploy
Uploading bundle files to /Workspace/Users/[USERNAME]/.bundle/[UNIQUE_NAME]/files...
Deploying resources...
Updating deployment state...
Deployment complete!

>>> jq select(.method == "POST" and (.path | contains("/clusters/resize"))) out.requests.txt
{
  "method": "POST",
  "path": "/api/2.1/clusters/resize",
  "body": {
    "autoscale": {
      "max_workers": 6,
      "min_workers": 4
    },
    "cluster_id": "[CLUSTER_ID]"
  }
}

=== Cluster should have new autoscale
{
  "cluster_name": "test-cluster-[UNIQUE_NAME]",
  "num_workers": null,
  "autoscale": {
    "max_workers": 6,
    "min_workers": 4
  }
}

=== Removing autoscale section should call resize API

Error: Test script killed due to a timeout
