
>>> [CLI] bundle deploy
Uploading bundle files to /Workspace/Users/[USERNAME]/.bundle/[UNIQUE_NAME]/files...
Deploying resources...
Updating deployment state...
Deployment complete!

=== Assert the pipeline is created with catalog
>>> [CLI] pipelines get [UUID]
{
  "spec": {
    "catalog": "main",
    "channel": "CURRENT",
    "deployment": {
      "kind": "BUNDLE",
      "metadata_file_path": "/Workspace/Users/[USERNAME]/.bundle/[UNIQUE_NAME]/state/metadata.json"
    },
    "development": true,
    "edition": "ADVANCED",
    "id": "[UUID]",
    "libraries": [
      {
        "notebook": {
          "path": "/Workspace/Users/[USERNAME]/.bundle/[UNIQUE_NAME]/files/nb"
        }
      }
    ],
    "name": "test-pipeline-[UNIQUE_NAME]",
    "target": "main.test-schema-[UNIQUE_NAME]"
  }
}

=== Switch from catalog to storage (triggers recreation)
>>> update_file.py databricks.yml catalog: main storage: dbfs:/my-storage

>>> update_file.py databricks.yml target: ${resources.schemas.bar.id} #target: ${resources.schemas.bar.id}

>>> [CLI] bundle plan
recreate pipelines.foo

Plan: 1 to add, 0 to change, 1 to delete, 1 unchanged

=== Redeploy the bundle (should recreate the pipeline)
>>> errcode [CLI] bundle deploy --force-lock
Uploading bundle files to /Workspace/Users/[USERNAME]/.bundle/[UNIQUE_NAME]/files...

This action will result in the deletion or recreation of the following Lakeflow Spark Declarative Pipelines along with the
Streaming Tables (STs) and Materialized Views (MVs) managed by them. Recreating the pipelines will
restore the defined STs and MVs through full refresh. Note that recreation is necessary when pipeline
properties such as the 'catalog' or 'storage' are changed:
  recreate resources.pipelines.foo
Error: the deployment requires destructive actions, but current console does not support prompting. Please specify --auto-approve if you would like to skip prompts and proceed


Exit code: 1

>>> [CLI] bundle destroy --auto-approve
The following resources will be deleted:
  delete resources.pipelines.foo
  delete resources.schemas.bar

This action will result in the deletion of the following UC schemas. Any underlying data may be lost:
  delete resources.schemas.bar

This action will result in the deletion of the following Lakeflow Spark Declarative Pipelines along with the
Streaming Tables (STs) and Materialized Views (MVs) managed by them:
  delete resources.pipelines.foo

All files and directories at the following location will be deleted: /Workspace/Users/[USERNAME]/.bundle/[UNIQUE_NAME]

Deleting files...
Destroy complete!
