export WAREHOUSE_ID="$TEST_DEFAULT_WAREHOUSE_ID"

cleanup() {
    trace $CLI bundle destroy --auto-approve
    rm out.requests.txt
}
trap cleanup EXIT

# Create the dashboard with initial warehouse_id
envsubst < databricks.yml.tmpl > databricks.yml
trace $CLI bundle plan
trace $CLI bundle deploy
dashboard_id=$($CLI bundle summary --output json | jq -r '.resources.dashboards.my_dashboard.id')
trace $CLI lakeview get $dashboard_id | jq '{display_name, lifecycle_state, parent_path, path, serialized_dashboard, warehouse_id}'

# Get published dashboard to show warehouse_id
trace $CLI lakeview get-published $dashboard_id | jq '{warehouse_id, embed_credentials}'

# Change the warehouse_id - this should trigger an update (not recreate)
export WAREHOUSE_ID="$TEST_SECONDARY_WAREHOUSE_ID"
envsubst < databricks.yml.tmpl > databricks.yml
trace $CLI bundle plan
trace $CLI bundle deploy
trace $CLI lakeview get $dashboard_id | jq '{display_name, lifecycle_state, parent_path, path, serialized_dashboard, warehouse_id}'

# Verify the warehouse_id was updated
trace $CLI lakeview get-published $dashboard_id | jq '{warehouse_id, embed_credentials}'

# Print API requests made to create parent_path or create / update the dashboard.
cat out.requests.txt | \
 jq 'select(.method == "POST" or .method == "PATCH")' | \
 jq 'select( (.path | contains("/api/2.0/lakeview/dashboards")) or ((.path == "/api/2.0/workspace/mkdirs") and (.body.path | contains("/default/resources"))))' \
 > out.requests.$DATABRICKS_BUNDLE_ENGINE.txt
