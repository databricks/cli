cleanup() {
    trace $CLI bundle destroy --auto-approve
    rm out.requests.txt
}
trap cleanup EXIT

# Deploy the dashboard and capture the ID
deploy_dashboard() {
    envsubst < databricks.yml.tmpl > databricks.yml
    envsubst < dashboard.tmpl > dash.lvdash.json
    trace $CLI bundle plan
    trace $CLI bundle deploy
    dashboard_id=$($CLI bundle summary --output json | jq -r '.resources.dashboards.my_dashboard.id')

    trace $CLI lakeview get $dashboard_id | jq '{display_name, lifecycle_state, parent_path, path, warehouse_id}'
    trace $CLI lakeview get $dashboard_id | jq '.serialized_dashboard | fromjson' | jq -S '.pages[0]'
}

# Create the dashboard with initial serialized_dashboard
export PAGE_NAME="name1"
deploy_dashboard

# Change the serialized_dashboard content - this should trigger an update (not recreate)
export PAGE_NAME="name2"
deploy_dashboard

# Print API requests made to create parent_path or create / update the dashboard.
# Terraform serialized OUTPUT_ONLY fields in the request body while direct-exp does not.
# That's why we write the requests to separate files.
cat out.requests.txt | \
 jq 'select(.method == "PATCH")' | \
 jq 'select( (.path | contains("/api/2.0/lakeview/dashboards")) or ((.path == "/api/2.0/workspace/mkdirs") and (.body.path | contains("/default/resources"))))' \
 > out.patch.requests.$DATABRICKS_BUNDLE_ENGINE.txt

cat out.requests.txt | \
 jq 'select(.method == "POST")' | \
 jq 'select( (.path | contains("/api/2.0/lakeview/dashboards")) or ((.path == "/api/2.0/workspace/mkdirs") and (.body.path | contains("/default/resources"))))' \
 > out.post.requests.txt
