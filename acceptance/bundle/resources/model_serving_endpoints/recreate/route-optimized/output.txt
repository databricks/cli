
>>> [CLI] bundle debug plan

>>> [CLI] bundle deploy
Uploading bundle files to /Workspace/Users/[USERNAME]/.bundle/[UNIQUE_NAME]/files...
Deploying resources...
Updating deployment state...
Deployment complete!

>>> [CLI] serving-endpoints get [ORIGINAL_ENDPOINT_ID]
null

>>> update_file.py databricks.yml route_optimized: false route_optimized: true

>>> [CLI] bundle debug plan

>>> [CLI] bundle deploy
Uploading bundle files to /Workspace/Users/[USERNAME]/.bundle/[UNIQUE_NAME]/files...
Deploying resources...
Updating deployment state...
Deployment complete!

>>> print_requests.py //serving-endpoints
{
  "method": "POST",
  "path": "/api/2.0/serving-endpoints",
  "body": {
    "config": {
      "served_entities": [
        {
          "external_model": {
            "name": "gpt-4o-mini",
            "openai_config": {
              "openai_api_key": "{{secrets/test-scope/openai-key}}"
            },
            "provider": "openai",
            "task": "llm/v1/chat"
          },
          "name": "prod"
        }
      ]
    },
    "name": "[ORIGINAL_ENDPOINT_ID]"
  }
}
{
  "method": "DELETE",
  "path": "/api/2.0/serving-endpoints/[ORIGINAL_ENDPOINT_ID]"
}
{
  "method": "POST",
  "path": "/api/2.0/serving-endpoints",
  "body": {
    "config": {
      "served_entities": [
        {
          "external_model": {
            "name": "gpt-4o-mini",
            "openai_config": {
              "openai_api_key": "{{secrets/test-scope/openai-key}}"
            },
            "provider": "openai",
            "task": "llm/v1/chat"
          },
          "name": "prod"
        }
      ]
    },
    "name": "[ORIGINAL_ENDPOINT_ID]",
    "route_optimized": true
  }
}

>>> [CLI] serving-endpoints get [ORIGINAL_ENDPOINT_ID]
true

>>> [CLI] bundle destroy --auto-approve
The following resources will be deleted:
  delete model_serving_endpoint test_endpoint

All files and directories at the following location will be deleted: /Workspace/Users/[USERNAME]/.bundle/[UNIQUE_NAME]

Deleting files...
Destroy complete!
