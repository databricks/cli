
>>> [CLI] bundle debug plan

>>> [CLI] bundle deploy
Uploading bundle files to /Workspace/Users/[USERNAME]/.bundle/[UNIQUE_NAME]/files...
Deploying resources...
Updating deployment state...
Deployment complete!

>>> [CLI] serving-endpoints get [ENDPOINT_ID]
"gpt-4o-mini"

>>> update_file.py databricks.yml name: gpt-4o-mini name: gpt-4o

>>> [CLI] bundle debug plan

>>> [CLI] bundle deploy
Uploading bundle files to /Workspace/Users/[USERNAME]/.bundle/[UNIQUE_NAME]/files...
Deploying resources...
Updating deployment state...
Deployment complete!

>>> print_requests.py //serving-endpoints
{
  "method": "POST",
  "path": "/api/2.0/serving-endpoints",
  "body": {
    "config": {
      "served_entities": [
        {
          "external_model": {
            "name": "gpt-4o-mini",
            "openai_config": {
              "openai_api_key": "{{secrets/test-scope/openai-key}}"
            },
            "provider": "openai",
            "task": "llm/v1/chat"
          },
          "name": "prod"
        }
      ]
    },
    "name": "[ENDPOINT_ID]"
  }
}
{
  "method": "PUT",
  "path": "/api/2.0/serving-endpoints/[ENDPOINT_ID]/config",
  "body": {
    "served_entities": [
      {
        "external_model": {
          "name": "gpt-4o",
          "openai_config": {
            "openai_api_key": "{{secrets/test-scope/openai-key}}"
          },
          "provider": "openai",
          "task": "llm/v1/chat"
        },
        "name": "prod"
      }
    ]
  }
}

>>> [CLI] serving-endpoints get [ENDPOINT_ID]
"gpt-4o"

>>> [CLI] bundle destroy --auto-approve
The following resources will be deleted:
  delete model_serving_endpoint test_endpoint

All files and directories at the following location will be deleted: /Workspace/Users/[USERNAME]/.bundle/[UNIQUE_NAME]

Deleting files...
Destroy complete!
