bundle:
  name: test-bundle

resources:
  jobs:
    sample_job:
      name: sample_job

      trigger:
        # Run this job every day, exactly one day from the last run; see https://docs.databricks.com/api/workspace/jobs/create#trigger
        periodic:
          interval: 1
          unit: DAYS

      tasks:
        - task_key: notebook_task
          notebook_task:
            notebook_path: sample_notebook.py
            source: WORKSPACE  # Without this, there is a different request between direct and terraform

      job_clusters:
        - job_cluster_key: job_cluster_autoscale
          new_cluster:
            spark_version: 16.4.x-scala2.12
            node_type_id:  $NODE_TYPE_ID
            data_security_mode: SINGLE_USER
            autoscale:
              min_workers: 1
              max_workers: 4

        # This config results in different request between terraform and direct:
        # Terraform removes "num_workers: 0" and direct sends it as is.
        # This is acceptable difference, users will get appropriate error message backend and can correct their config.
        #
        #- job_cluster_key: job_cluster_autoscale_num_workers0
        #  new_cluster:
        #    spark_version: 16.4.x-scala2.13
        #    node_type_id:  $NODE_TYPE_ID
        #    data_security_mode: SINGLE_USER
        #    autoscale:
        #      min_workers: 1
        #      max_workers: 4
        #    num_workers: 0

        - job_cluster_key: job_cluster_autoscale_num_workers1
          new_cluster:
            spark_version: 16.4.x-scala2.14
            node_type_id:  $NODE_TYPE_ID
            data_security_mode: SINGLE_USER
            autoscale:
              min_workers: 1
              max_workers: 4
            num_workers: 1

        - job_cluster_key: job_cluster_num_workers1
          new_cluster:
            spark_version: 16.4.x-scala2.15
            node_type_id:  $NODE_TYPE_ID
            data_security_mode: SINGLE_USER
            num_workers: 1

        - job_cluster_key: job_cluster_num_workers0
          new_cluster:
            spark_version: 16.4.x-scala2.16
            node_type_id:  $NODE_TYPE_ID
            data_security_mode: SINGLE_USER
            num_workers: 0
