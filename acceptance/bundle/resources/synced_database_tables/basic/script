envsubst < databricks.yml.tmpl > databricks.yml

# Create a unique source table for this test run to avoid hitting the 20-table-per-source limit
echo "Creating temporary source table: main.test_synced_$UNIQUE_NAME.trips_source"
# Create schema using CLI
$CLI schemas create test_synced_$UNIQUE_NAME main -o json | jq '{full_name}'
# Create source table from samples.nyctaxi.trips using SQL API
$CLI api post "/api/2.0/sql/statements/" --json "{
    \"warehouse_id\": \"$TEST_DEFAULT_WAREHOUSE_ID\",
    \"statement\": \"CREATE TABLE main.test_synced_$UNIQUE_NAME.trips_source AS SELECT * FROM samples.nyctaxi.trips LIMIT 10\",
    \"wait_timeout\": \"45s\"
  }" > /dev/null

cleanup() {
  trace $CLI bundle destroy --auto-approve
  # Clean up the temporary source table
  echo "Cleaning up temporary source table"
  $CLI tables delete main.test_synced_$UNIQUE_NAME.trips_source || true
  $CLI schemas delete main.test_synced_$UNIQUE_NAME || true
}
 trap cleanup EXIT

# test on fresh bundles
trace $CLI bundle summary

trace $CLI bundle validate
trace $CLI bundle deploy
trace $CLI bundle summary > out.summary.txt

# once again to test --force-pull flag (expect the same output; used to produce different output due to terraform.Interpolate() call)
trace $CLI bundle summary --force-pull > tmp.summary.txt
trace diff.py out.summary.txt tmp.summary.txt
rm tmp.summary.txt
