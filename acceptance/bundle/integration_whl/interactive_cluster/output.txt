{
    "project_name": "my_test_code",
    "spark_version": "13.3.x-snapshot-scala2.12",
    "node_type_id": "",
    "unique_id": "[UNIQUE_NAME]",
    "python_wheel_wrapper": false,
    "instance_pool_id": "[TEST_INSTANCE_POOL_ID]"
}
âœ¨ Successfully initialized template

>>> [CLI] bundle deploy
Building python_artifact...
Uploading my_test_code-0.0.1-py3-none-any.whl...
Uploading bundle files to /Workspace/Users/[USERNAME]/.bundle/[UNIQUE_NAME]/files...
Deploying resources...
Updating deployment state...
Deployment complete!

>>> [CLI] bundle run some_other_job
Run URL: [DATABRICKS_URL]/?o=[NUMID]#job/[NUMID]/run/[NUMID]

[TIMESTAMP] "[default] Test Wheel Job [UNIQUE_NAME]" RUNNING 
[TIMESTAMP] "[default] Test Wheel Job [UNIQUE_NAME]" TERMINATED SUCCESS 
Hello from my func
Got arguments:
['my_test_code', 'one', 'two']

>>> [CLI] bundle destroy --auto-approve
The following resources will be deleted:
  delete job some_other_job

All files and directories at the following location will be deleted: /Workspace/Users/[USERNAME]/.bundle/[UNIQUE_NAME]

Deleting files...
Destroy complete!
