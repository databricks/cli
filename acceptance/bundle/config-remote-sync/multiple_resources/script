#!/bin/bash

envsubst < databricks.yml.tmpl > databricks.yml

cleanup() {
  # Restore original config before destroy to avoid Terraform errors
  # from server-side-only fields (e.g. creator_name) written by config-remote-sync.
  envsubst < databricks.yml.tmpl > databricks.yml
  trace $CLI bundle destroy --auto-approve
}
trap cleanup EXIT

touch dummy.whl
$CLI bundle deploy

job_one_id="$(read_id.py job_one)"
job_two_id="$(read_id.py job_two)"
read_id.py test_cluster > /dev/null
read_id.py test_experiment > /dev/null
read_id.py test_model > /dev/null
read_id.py test_volume > /dev/null
read_id.py test_warehouse > /dev/null

# Add replacements for dynamic values that appear in server-side defaults
add_repl.py "$($CLI current-user me | jq -r .id)" "USER_ID"
add_repl.py "$($CLI metastores current | jq -r .metastore_id)" "METASTORE_ID"

title "Modify both jobs"
edit_resource.py jobs $job_one_id <<EOF
r["max_concurrent_runs"] = 5
r["tags"] = {"team": "data"}
EOF

edit_resource.py jobs $job_two_id <<EOF
r["max_concurrent_runs"] = 10
r["tags"] = {"team": "ml"}
EOF

title "Detect and save changes"
echo
cp databricks.yml databricks.yml.backup
$CLI bundle config-remote-sync --save

title "Configuration changes"
echo
trace diff.py databricks.yml.backup databricks.yml
rm databricks.yml.backup
