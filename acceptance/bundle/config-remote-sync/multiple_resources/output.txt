Uploading bundle files to /Workspace/Users/[USERNAME]/.bundle/test-bundle-[UNIQUE_NAME]/default/files...
Deploying resources...
Updating deployment state...
Deployment complete!

=== Modify both jobs
=== Detect and save changes
Detected changes in 7 resource(s):

Resource: resources.clusters.test_cluster
  aws_attributes: add
  data_security_mode: add
  driver_node_type_id: add

Resource: resources.experiments.test_experiment
  artifact_location: add

Resource: resources.jobs.job_one
  max_concurrent_runs: replace
  tags: add

Resource: resources.jobs.job_two
  max_concurrent_runs: replace
  tags: add

Resource: resources.registered_models.test_model
  full_name: add
  metastore_id: add
  owner: add

Resource: resources.sql_warehouses.test_warehouse
  creator_name: add
  min_num_clusters: add
  warehouse_type: add

Resource: resources.volumes.test_volume
  storage_location: add



=== Configuration changes

>>> diff.py databricks.yml.backup databricks.yml
--- databricks.yml.backup
+++ databricks.yml
@@ -5,5 +5,5 @@
   jobs:
     job_one:
-      max_concurrent_runs: 1
+      max_concurrent_runs: 5
       tasks:
         - task_key: main
@@ -15,6 +15,8 @@
             num_workers: 1

+      tags:
+        team: data
     job_two:
-      max_concurrent_runs: 2
+      max_concurrent_runs: 10
       tasks:
         - task_key: main
@@ -26,4 +28,6 @@
             num_workers: 1

+      tags:
+        team: ml
   clusters:
     test_cluster:
@@ -33,8 +37,14 @@
       num_workers: 1

+      aws_attributes:
+        availability: SPOT_WITH_FALLBACK
+        zone_id: us-east-1c
+      data_security_mode: SINGLE_USER
+      driver_node_type_id: [NODE_TYPE_ID]
   experiments:
     test_experiment:
       name: /Users/[USERNAME]/experiment-[UNIQUE_NAME]

+      artifact_location: dbfs:/databricks/mlflow-tracking/[NUMID]
   registered_models:
     test_model:
@@ -43,4 +53,7 @@
       schema_name: default

+      full_name: main.default.model_[UNIQUE_NAME]
+      metastore_id: [UUID]
+      owner: [USERNAME]
   volumes:
     test_volume:
@@ -50,6 +63,10 @@
       volume_type: MANAGED

+      storage_location: s3://deco-uc-prod-isolated-aws-us-east-1/metastore/[UUID]/volumes/[UUID]
   sql_warehouses:
     test_warehouse:
       name: warehouse-[UNIQUE_NAME]
       cluster_size: 2X-Small
+      creator_name: [USERNAME]
+      min_num_clusters: 1
+      warehouse_type: CLASSIC

>>> [CLI] bundle destroy --auto-approve
The following resources will be deleted:
  delete resources.clusters.test_cluster
  delete resources.experiments.test_experiment
  delete resources.jobs.job_one
  delete resources.jobs.job_two
  delete resources.registered_models.test_model
  delete resources.sql_warehouses.test_warehouse
  delete resources.volumes.test_volume

This action will result in the deletion of the following volumes.
For managed volumes, the files stored in the volume are also deleted from your
cloud tenant within 30 days. For external volumes, the metadata about the volume
is removed from the catalog, but the underlying files are not deleted:
  delete resources.volumes.test_volume

All files and directories at the following location will be deleted: /Workspace/Users/[USERNAME]/.bundle/test-bundle-[UNIQUE_NAME]/default

Deleting files...
Destroy complete!
