Uploading bundle files to /Workspace/Users/[USERNAME]/.bundle/test-bundle-[UNIQUE_NAME]/default/files...
Deploying resources...
Updating deployment state...
Deployment complete!

=== Modify pipeline_task full_refresh to True
=== Modify pipeline development to True
=== Detect and save changes
Detected changes in 2 resource(s):

Resource: resources.jobs.my_job
  tasks[task_key='run_pipeline'].pipeline_task.full_refresh: replace

Resource: resources.pipelines.my_pipeline
  development: replace



=== Configuration changes

>>> diff.py databricks.yml.backup databricks.yml
--- databricks.yml.backup
+++ databricks.yml
@@ -6,5 +6,5 @@
     my_pipeline:
       name: test-pipeline-[UNIQUE_NAME]
-      development: false
+      development: true
       libraries:
         - notebook:
@@ -17,3 +17,3 @@
           pipeline_task:
             pipeline_id: ${resources.pipelines.my_pipeline.id}
-            full_refresh: false
+            full_refresh: true

>>> [CLI] bundle destroy --auto-approve
The following resources will be deleted:
  delete resources.jobs.my_job
  delete resources.pipelines.my_pipeline

This action will result in the deletion of the following Lakeflow Spark Declarative Pipelines along with the
Streaming Tables (STs) and Materialized Views (MVs) managed by them:
  delete resources.pipelines.my_pipeline

All files and directories at the following location will be deleted: /Workspace/Users/[USERNAME]/.bundle/test-bundle-[UNIQUE_NAME]/default

Deleting files...
Destroy complete!
