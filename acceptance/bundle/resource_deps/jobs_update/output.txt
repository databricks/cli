
>>> [CLI] bundle plan
create jobs.bar
create jobs.foo

Plan: 2 to add, 0 to change, 0 to delete, 0 unchanged

>>> [CLI] bundle deploy
Uploading bundle files to /Workspace/Users/[USERNAME]/.bundle/test-bundle/default/files...
Deploying resources...
Updating deployment state...
Deployment complete!

>>> print_requests.py //jobs
{
  "method": "POST",
  "path": "/api/2.2/jobs/create",
  "body": {
    "deployment": {
      "kind": "BUNDLE",
      "metadata_file_path": "/Workspace/Users/[USERNAME]/.bundle/test-bundle/default/state/metadata.json"
    },
    "edit_mode": "UI_LOCKED",
    "format": "MULTI_TASK",
    "job_clusters": [
      {
        "job_cluster_key": "key",
        "new_cluster": {
          "num_workers": 0,
          "spark_version": "13.3.x-scala2.12"
        }
      }
    ],
    "max_concurrent_runs": 1,
    "name": "foo",
    "queue": {
      "enabled": true
    },
    "trigger": {
      "pause_status": "UNPAUSED",
      "periodic": {
        "interval": 1,
        "unit": "DAYS"
      }
    }
  }
}
{
  "method": "POST",
  "path": "/api/2.2/jobs/create",
  "body": {
    "deployment": {
      "kind": "BUNDLE",
      "metadata_file_path": "/Workspace/Users/[USERNAME]/.bundle/test-bundle/default/state/metadata.json"
    },
    "description": "depends on foo id [FOO_ID]",
    "edit_mode": "UI_LOCKED",
    "format": "MULTI_TASK",
    "max_concurrent_runs": 1,
    "name": "bar",
    "queue": {
      "enabled": true
    }
  }
}

>>> [CLI] bundle plan
Plan: 0 to add, 0 to change, 0 to delete, 2 unchanged

=== Update trigger.periodic.unit and re-deploy; jobs.bar is unchanged
>>> update_file.py databricks.yml DAYS HOURS

>>> [CLI] bundle plan
update jobs.foo

Plan: 0 to add, 1 to change, 0 to delete, 1 unchanged

>>> [CLI] bundle deploy
Uploading bundle files to /Workspace/Users/[USERNAME]/.bundle/test-bundle/default/files...
Deploying resources...
Updating deployment state...
Deployment complete!

>>> print_requests.py //jobs
{
  "method": "POST",
  "path": "/api/2.2/jobs/reset",
  "body": {
    "job_id": [FOO_ID],
    "new_settings": {
      "deployment": {
        "kind": "BUNDLE",
        "metadata_file_path": "/Workspace/Users/[USERNAME]/.bundle/test-bundle/default/state/metadata.json"
      },
      "edit_mode": "UI_LOCKED",
      "email_notifications": {},
      "format": "MULTI_TASK",
      "job_clusters": [
        {
          "job_cluster_key": "key",
          "new_cluster": {
            "num_workers": 0,
            "spark_version": "13.3.x-scala2.12"
          }
        }
      ],
      "max_concurrent_runs": 1,
      "name": "foo",
      "queue": {
        "enabled": true
      },
      "run_as": {
        "user_name": "[USERNAME]"
      },
      "trigger": {
        "pause_status": "UNPAUSED",
        "periodic": {
          "interval": 1,
          "unit": "HOURS"
        }
      },
      "webhook_notifications": {}
    }
  }
}

>>> [CLI] bundle plan
Plan: 0 to add, 0 to change, 0 to delete, 2 unchanged

=== Fetch job ID and verify remote state
>>> [CLI] jobs get [FOO_ID]
{
  "created_time":[UNIX_TIME_MILLIS][0],
  "creator_user_name":"[USERNAME]",
  "job_id":[FOO_ID],
  "run_as_user_name":"[USERNAME]",
  "settings": {
    "deployment": {
      "kind":"BUNDLE",
      "metadata_file_path":"/Workspace/Users/[USERNAME]/.bundle/test-bundle/default/state/metadata.json"
    },
    "edit_mode":"UI_LOCKED",
    "email_notifications": {},
    "format":"MULTI_TASK",
    "job_clusters": [
      {
        "job_cluster_key":"key",
        "new_cluster": {
          "num_workers":0,
          "spark_version":"13.3.x-scala2.12"
        }
      }
    ],
    "max_concurrent_runs":1,
    "name":"foo",
    "queue": {
      "enabled":true
    },
    "run_as": {
      "user_name":"[USERNAME]"
    },
    "timeout_seconds":0,
    "trigger": {
      "pause_status":"UNPAUSED",
      "periodic": {
        "interval":1,
        "unit":"HOURS"
      }
    },
    "webhook_notifications": {}
  }
}

>>> [CLI] jobs get [BAR_ID]
{
  "created_time":[UNIX_TIME_MILLIS][1],
  "creator_user_name":"[USERNAME]",
  "job_id":[BAR_ID],
  "run_as_user_name":"[USERNAME]",
  "settings": {
    "deployment": {
      "kind":"BUNDLE",
      "metadata_file_path":"/Workspace/Users/[USERNAME]/.bundle/test-bundle/default/state/metadata.json"
    },
    "description":"depends on foo id [FOO_ID]",
    "edit_mode":"UI_LOCKED",
    "email_notifications": {},
    "format":"MULTI_TASK",
    "max_concurrent_runs":1,
    "name":"bar",
    "queue": {
      "enabled":true
    },
    "timeout_seconds":0,
    "webhook_notifications": {}
  }
}

>>> [CLI] bundle destroy --auto-approve
The following resources will be deleted:
  delete job bar
  delete job foo

All files and directories at the following location will be deleted: /Workspace/Users/[USERNAME]/.bundle/test-bundle/default

Deleting files...
Destroy complete!

>>> print_requests.py --sort //jobs
{
  "method": "POST",
  "path": "/api/2.2/jobs/delete",
  "body": {
    "job_id": [FOO_ID]
  }
}
{
  "method": "POST",
  "path": "/api/2.2/jobs/delete",
  "body": {
    "job_id": [BAR_ID]
  }
}

>>> musterr [CLI] jobs get [FOO_ID]
Error: Not Found

>>> musterr [CLI] jobs get [BAR_ID]
Error: Not Found
